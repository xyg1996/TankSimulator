#!/bin/bash
echo 开始流体准备！
currentpath=$1
echo $currentpath
cd $currentpath

unset PATH
unset PYTHONPATH
unset PYTHONHOME
PATH=/opt/skyformai/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
unset LIBRARY_PATH
unset LD_LIBRARY_PATH
unset CPLUS_INCLUDE_PATH
unset PKG_CONFIG_PATH

source ~/.bashrc
source /share/simforge_share/open-source/spack/share/spack/setup-env.sh
# spack env activate precice
# spack load precice@2.3.0%gcc@10.2.0
# spack load gcc@10.2.0

# YAML_ROOT=/share/simforge_share/open-source/CalculiX/2.16-calculix-adapter/yaml-cpp-yaml-cpp-0.6.2
# export LD_LIBRARY_PATH=$YAML_ROOT/build:$YAML_ROOT/lib:$LD_LIBRARY_PATH
# export CPLUS_INCLUDE_PATH=$YAML_ROOT/include:$CPLUS_INCLUDE_PATH

# export MPI_ROOT=/share/simforge_share/open-source/spack/opt/spack/linux-centos7-cascadelake/gcc-10.2.0/openmpi-4.1.2-rlo4quziwcyvnoridzvryrx7f445wijp
# export INSTALL_ROOT=/share/simforge_share/open-source/CalculiX/2.16-calculix-adapter/OpenFOAM-6
# export PATH=$MPI_ROOT/bin:$INSTALL_ROOT/platforms/linux64GccDPInt32Opt/bin/:$INSTALL_ROOT/bin:$PATH
# export LD_LIBRARY_PATH=$MPI_ROOT/lib:$INSTALL_ROOT/platforms/linux64GccDPInt32Opt/lib:$LD_LIBRARY_PATH
# source $INSTALL_ROOT/etc/bashrc
# spack load gcc@5.4.0
# spack load precice@1.6.1
# export MPI_ROOT=/share/simforge_share/open-source/spack/opt/\
# spack/linux-centos7-broadwell/gcc-5.4.0/openmpi-4.1.4-jii5go43xw3lrfzuzqzglqm43lqezq3i
# export Openfoam_ROOT=/share/simforge_share/open-source/CalculiX/\
# 2.15-calculix-adapter-openfoam/OpenFOAM-6
# export PATH=$MPI_ROOT/bin:$Openfoam_ROOT/platforms/\
# linux64GccDPInt32Opt/bin:$Openfoam_ROOT/bin:$PATH
# export LD_LIBRARY_PATH=$MPI_ROOT/lib:$Openfoam_ROOT/platforms/\
# linux64GccDPInt32Opt/lib:$Openfoam_ROOT/../ThirdParty-6.0/platforms/\
# linux64GccDPInt32/lib:$LD_LIBRARY_PATH
# source $Openfoam_ROOT/etc/bashrc
source /share/simforge_share/open-source/CalculiX/2.15-calculix-adapter-openfoam/build_env.sh
. $WM_PROJECT_DIR/bin/tools/RunFunctions

# Fluid participant

# Run this script in one terminal and the "runSolid" script in another terminal.
# These scripts present how the two participants would be started manually.
# Alternatively, you may execute the "Allrun" script in one terminal.

# Run this script with "-parallel" for parallel simulations

# The script "Allclean" cleans-up the result and log files.

# 1 for true, 0 for false
parallel=1
if [ "$1" = "-parallel" ]; then
    parallel=1
fi

echo "Preparing and running the Fluid participant..."

# Prepare
if [ $parallel -eq 1 ]; then
    ln -s -f precice-config_parallel.xml precice-config.xml
else
    ln -s -f precice-config_serial.xml precice-config.xml
fi

# Mesh
cd Fluid
    procs=$(getNumberOfProcessors)
cd ..

#rm -rfv Fluid/0/*
#cp -r Fluid/0.orig/ Fluid/0/
blockMesh -case Fluid &&
decomposePar -case Fluid -force &&

cd Fluid

echo "generate fluid mesh...."
csub -I -q q_x86_sf -n $procs -o log.SHM ompi-mpirun snappyHexMesh -overwrite -parallel &&

reconstructParMesh -mergeTol 1e-6 -constant &&
reconstructPar -constant &&

renumberMesh -overwrite &&

checkMesh &&

echo "set the initial fields...."
setFields &&


# Run
# cd Fluid
solver=$(getApplication)
cd ..
echo $solver

decomposePar -case Fluid -force &&

# ln -s -f precice-config_parallel.xml precice-config.xml

# yes | cp -rf Fluid/constant/g_ac Fluid/constant/g
# yes | cp -rf Fluid/system/controlDict_ac Fluid/system/controlDict
# /usr/sw-mpp/bin/bsub -I -q q_x86_share -n $procs -o log.$solver $solver -parallel -case Fluid &&

# yes | cp -rf Fluid/constant/g_sh Fluid/constant/g
# yes | cp -rf Fluid/system/controlDict_sh Fluid/system/controlDict
# /usr/sw-mpp/bin/bsub -I -q q_x86_share -n $procs -o log.$solver $solver -parallel -case Fluid &&

echo 流体准备已结束,生成在如下的目录：
echo $currentpath
echo 请点击开始计算继续

